{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95ebc06",
   "metadata": {},
   "source": [
    "# Convert Keras .h5 Model to TensorFlow SavedModel Format\n",
    "\n",
    "This notebook shows steps to convert keras model to tensorflow format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e402e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load the keras model (Xception) from the url and save it as 'clothing-model-v4.h5'\n",
    "if not os.path.isfile('clothing-model-v4.h5'):\n",
    "    !wget https://github.com/alexeygrigorev/mlbookcamp-code/releases/download/chapter7-model/xception_v4_large_08_0.894.h5 -O clothing-model-v4.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed4d6d",
   "metadata": {},
   "source": [
    "Convert keras `.h5` to tensorflow `save` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65269636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 15:34:34.790584: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 12582912 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load keras model\n",
    "model = keras.models.load_model('./clothing-model-v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82da08b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fdcae5125c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb4cd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clothing-model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clothing-model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model in tensorflow format\n",
    "tf.saved_model.save(model, 'clothing-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "243e1572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothing-model\t      gRFC-tf-serving-connection.ipynb\r\n",
      "clothing-model-v4.h5  h5model-to-saved.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db22a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tsaved_model.pb\tvariables\r\n"
     ]
    }
   ],
   "source": [
    "# Take a look what's inside 'clothing-model' folder\n",
    "!ls clothing-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c3f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tree clothing-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f1a96",
   "metadata": {},
   "source": [
    "Let's take a look what's inside the saved model using the `saved_model_cli` utility that comes with tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5c1e99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_8'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 299, 299, 3)\n",
      "        name: serving_default_input_8:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_7'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir clothing-model --all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f654201",
   "metadata": {},
   "source": [
    "**We are interested in the signature, specifically the following one:**\n",
    "\n",
    "```\n",
    "signature_def['serving_default']:\n",
    "  The given SavedModel SignatureDef contains the following input(s):\n",
    "    inputs['input_8'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 299, 299, 3)\n",
    "        name: serving_default_input_8:0\n",
    "  The given SavedModel SignatureDef contains the following output(s):\n",
    "    outputs['dense_7'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 10)\n",
    "        name: StatefulPartitionedCall:0\n",
    "  Method name is: tensorflow/serving/predict\n",
    "```\n",
    "\n",
    "This signature definition has the name `serving_default` that we need to invoke our model, then we have the name of the inputs (`input_8`) that can take arbitrary number of images (hence batch `-1`) of shape `(299 ,299, 3)` and the outputs name (`dense_7`) of arbitrary images of shape (`10`).\n",
    "\n",
    "We need to take note of the these names:\n",
    "\n",
    "- `serving_default` - signature\n",
    "- `input_8` - input\n",
    "- `dense_7` - output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
